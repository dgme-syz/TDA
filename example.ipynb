{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], return_tensors=\"pt\", padding=True)\n",
    "# outputs = model(**inputs)\n",
    "# logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "# probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49406,   320,  1125,   539,   320,  2368, 49407],\n",
      "        [49406,   320,  1125,   539,   320,  1929, 49407]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor(text=[\"a photo of a cat\", \"a photo of a dog\"], return_tensors=\"pt\", padding=True, trucation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(b[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"b\"] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', 1), ('b', 2)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "c = ds[\"train\"].info.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple_pie\n",
      "0\n",
      "101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"{c.int2str(0)}\\n\"\n",
    "    f\"{c.str2int('apple_pie')}\\n\"\n",
    "    f\"{c.num_classes}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\n",
    "    a[[0, 1], [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from queue import PriorityQueue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(a[0].get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = PriorityQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1] = PriorityQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys([0, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def compute_cache_logits(image_features, cache, alpha, beta, clip_weights, neg_mask_thresholds=None):\n",
    "    \"\"\"Compute logits using positive/negative cache.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        cache_keys = []\n",
    "        cache_values = []\n",
    "        for class_index in sorted(cache.keys()):\n",
    "            for item in cache[class_index]:\n",
    "                cache_keys.append(item[0])\n",
    "                if neg_mask_thresholds:\n",
    "                    cache_values.append(item[2])\n",
    "                else:\n",
    "                    cache_values.append(class_index)\n",
    "\n",
    "        cache_keys = torch.cat(cache_keys, dim=0).permute(1, 0)\n",
    "        if neg_mask_thresholds:\n",
    "            cache_values = torch.cat(cache_values, dim=0)\n",
    "            cache_values = (((cache_values > neg_mask_thresholds[0]) & (cache_values < neg_mask_thresholds[1])).type(torch.int8)).cuda().half()\n",
    "        else:\n",
    "            cache_values = (F.one_hot(torch.Tensor(cache_values).to(torch.int64), num_classes=clip_weights.size(1))).cuda().half()\n",
    "\n",
    "        affinity = image_features @ cache_keys\n",
    "        cache_logits = ((-1) * (beta - beta * affinity)).exp() @ cache_values\n",
    "        return alpha * cache_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PriorityQueue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mPriorityQueue\u001b[49m()\n\u001b[0;32m      2\u001b[0m a\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m a\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PriorityQueue' is not defined"
     ]
    }
   ],
   "source": [
    "a = PriorityQueue()\n",
    "a.put(1)\n",
    "a.put(2)\n",
    "a.put(3)\n",
    "a.put(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for x in a.queue:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "print(\n",
    "    a[:2] + [a[2]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.randn((1, 2)), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.randn((1, 2)), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 7)\n",
      "(2, 5, 8)\n",
      "(3, 6, 9)\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = [7, 8, 9]\n",
    "\n",
    "for x in zip(a, b, c):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PriorityQueue(maxsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.put(1)\n",
    "a.put(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    x: int\n",
    "    y: int\n",
    "    def __iter__(self):\n",
    "        return iter([self.x, self.y])\n",
    "    \n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.x = 1\n",
    "a.y = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.1403, -0.1369],\n",
       "         [ 0.2447,  0.6363]]),\n",
       " tensor([[ 1.6144,  0.1036],\n",
       "         [-1.6141, -0.2780]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "list((torch.randn(2, 2), torch.randn(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8343,  0.8018])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(torch.randn(2, 2).unbind(dim=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_dict({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "fn = lambda x: {\n",
    "        \"a\": [torch.randn((2, 2)) for _ in x[\"a\"]],\n",
    "        \"b\": x[\"b\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [tensor([[ 0.3739,  0.1242],\n",
       "          [-0.3914, -0.8448]]),\n",
       "  tensor([[-0.5382, -0.7050],\n",
       "          [-0.8535,  1.9457]])],\n",
       " 'b': [4, 5]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn(ds[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"barkermrl/imagenet-a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label', 'origin', 'english_label'],\n",
       "        num_rows: 10980\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_wordnet_to_cls(name: str):\n",
    "    from nltk.corpus import wordnet\n",
    "    return wordnet.synset_from_pos_and_offset(\n",
    "        'n', int(re.search(r\"^n(\\d{8})$\", name).group(1))\n",
    "    ).name().split('.')[0]\n",
    "\n",
    "a = ds[\"train\"].info.features[\"label\"].names\n",
    "a = [convert_wordnet_to_cls(x) for x in a]\n",
    "\n",
    "with open(\"imagenet-a.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n01498041'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.int2str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goldfinch'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "wordnet.synset_from_pos_and_offset('n', 1531178).name().split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\17299\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = re.search(r\"^n(\\d{8})$\", \"n01498041\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498041"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(p.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
